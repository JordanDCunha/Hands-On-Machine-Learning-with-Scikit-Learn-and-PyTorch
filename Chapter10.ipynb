{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE8uBMoPdqyvtcFLYHh+T+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanDCunha/Hands-On-Machine-Learning-with-Scikit-Learn-and-PyTorch/blob/main/Chapter10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Fundamentals\n",
        "\n",
        "The core data structure of PyTorch is the **tensor**. Itâ€™s a multidimensional array with a shape and a data type, used for numerical computations.\n",
        "\n",
        "At first glance, tensors look a lot like NumPy arrays â€” and thatâ€™s true â€” but they have two major advantages:\n",
        "\n",
        "1. They can live on a **GPU or other hardware accelerators**\n",
        "2. They support **automatic differentiation (autograd)**\n",
        "\n",
        "Every neural network we build in PyTorch will take tensors as input and output tensors, much like Scikit-Learn models work with NumPy arrays.\n",
        "\n",
        "Letâ€™s start by learning how to create and manipulate tensors.\n"
      ],
      "metadata": {
        "id": "R_HtVOeq9ayb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Tensors\n",
        "\n",
        "First, letâ€™s import PyTorch.\n"
      ],
      "metadata": {
        "id": "oykxJjuh9dwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "metadata": {
        "id": "TJrz3XBb9f5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create a PyTorch tensor much like a NumPy array. For example, hereâ€™s a 2 Ã— 3 tensor:\n"
      ],
      "metadata": {
        "id": "SOfp69OKCSsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1.0, 4.0, 7.0],\n",
        "                  [2.0, 3.0, 6.0]])\n",
        "X\n"
      ],
      "metadata": {
        "id": "4fO0MjpaCTZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensor has a **shape** and a **data type**:\n"
      ],
      "metadata": {
        "id": "csEG7OpkCUNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype\n"
      ],
      "metadata": {
        "id": "mruBmLUMCW4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing works just like NumPy:\n"
      ],
      "metadata": {
        "id": "ShJrz0NICXi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[0, 1]\n"
      ],
      "metadata": {
        "id": "LYz9BMNzCYO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:, 1]\n"
      ],
      "metadata": {
        "id": "YnM-_XVRCZFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch supports a wide range of mathematical operations, with an API very similar to NumPy.\n"
      ],
      "metadata": {
        "id": "oog__v_mCZ-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "10 * (X + 1.0)\n"
      ],
      "metadata": {
        "id": "PJyQlKNzJp6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.exp()\n"
      ],
      "metadata": {
        "id": "5zX4LGknJqhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.mean()\n"
      ],
      "metadata": {
        "id": "4WyI1ZqPJrEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.max(dim=0)\n"
      ],
      "metadata": {
        "id": "jfbmD5yFJtEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X @ X.T\n"
      ],
      "metadata": {
        "id": "UkQ-d-KvJt4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**  \n",
        "PyTorch prefers the argument name `dim`, but it also supports `axis` like NumPy.\n"
      ],
      "metadata": {
        "id": "wtZVQEE6Ju-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting Between NumPy and PyTorch\n"
      ],
      "metadata": {
        "id": "E78SjI8rJvwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X.numpy()\n"
      ],
      "metadata": {
        "id": "b54z5rIDJwuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(np.array([[1., 4., 7.],\n",
        "                       [2., 3., 6.]]))\n"
      ],
      "metadata": {
        "id": "fNvODYDcJxhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch defaults to **32-bit floats**, while NumPy defaults to **64-bit floats**.\n",
        "\n",
        "For deep learning, 32-bit precision is usually preferred because it:\n",
        "- Uses less memory\n",
        "- Runs faster\n",
        "- Is precise enough for neural networks\n"
      ],
      "metadata": {
        "id": "hAQuknfRJy-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.FloatTensor(np.array([[1., 4., 7.],\n",
        "                            [2., 3., 6.]]))\n"
      ],
      "metadata": {
        "id": "SO3zP2n1J0bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Tip**  \n",
        "`torch.from_numpy()` avoids copying data, but changes to one will affect the other.\n"
      ],
      "metadata": {
        "id": "hLKx-02PJ1WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[:, 1] = -99\n",
        "X\n"
      ],
      "metadata": {
        "id": "g9alvkE1J2T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.relu_()\n",
        "X\n"
      ],
      "metadata": {
        "id": "5yYdvSalJ3Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In-place operations end with an underscore (`_`), such as `relu_()` or `sqrt_()`.\n",
        "\n",
        "They save memory, but must be used carefully when working with autograd.\n"
      ],
      "metadata": {
        "id": "XepX8pU1J4hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hardware Acceleration\n"
      ],
      "metadata": {
        "id": "EMqq4qfvJ5P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "device\n"
      ],
      "metadata": {
        "id": "RyeSIXBkJ6Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = torch.tensor([[1., 2., 3.],\n",
        "                  [4., 5., 6.]])\n",
        "M = M.to(device)\n",
        "M.device\n"
      ],
      "metadata": {
        "id": "O1EzUTuRJ7Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = torch.tensor([[1., 2., 3.],\n",
        "                  [4., 5., 6.]], device=device)\n"
      ],
      "metadata": {
        "id": "R8ibWJsvJ8Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R = M @ M.T\n",
        "R\n"
      ],
      "metadata": {
        "id": "Tv7eRc9NJ9Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s compare CPU vs GPU performance for matrix multiplication.\n"
      ],
      "metadata": {
        "id": "hJpPgESFJ8Ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = torch.rand((1000, 1000))\n",
        "%timeit M @ M.T\n"
      ],
      "metadata": {
        "id": "ZKDzowcdJ_EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = torch.rand((1000, 1000), device=\"cuda\")\n",
        "%timeit M @ M.T\n"
      ],
      "metadata": {
        "id": "YxWnUj1mKAP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs shine when operations are large and parallelizable. For very small tensors, the CPU can actually be faster.\n"
      ],
      "metadata": {
        "id": "GTYRM_suKBLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd (Automatic Differentiation)\n"
      ],
      "metadata": {
        "id": "SBlVNZTGKCHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "f = x ** 2\n",
        "f.backward()\n",
        "x.grad\n"
      ],
      "metadata": {
        "id": "Vwm8nTf6KC7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch dynamically builds a computation graph during the forward pass and uses it to compute gradients during the backward pass.\n"
      ],
      "metadata": {
        "id": "3tJaWh3CKDyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "with torch.no_grad():\n",
        "    x -= learning_rate * x.grad\n"
      ],
      "metadata": {
        "id": "z9rLBJO9KEqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n"
      ],
      "metadata": {
        "id": "b2TxI2g5KFiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Gradient Descent Loop\n"
      ],
      "metadata": {
        "id": "aAxnwFzHKGQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "\n",
        "for iteration in range(100):\n",
        "    f = x ** 2\n",
        "    f.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x -= learning_rate * x.grad\n",
        "\n",
        "    x.grad.zero_()\n",
        "\n",
        "x\n"
      ],
      "metadata": {
        "id": "8CnUEhauKHKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be careful with **in-place operations** when using autograd. Some operations store their outputs or inputs for the backward pass, and modifying them in place can break gradient computation.\n"
      ],
      "metadata": {
        "id": "Szr8AgW0LUmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "You now know how to:\n",
        "- Create and manipulate PyTorch tensors\n",
        "- Move tensors between CPU and GPU\n",
        "- Use autograd to compute gradients\n",
        "- Implement gradient descent manually\n",
        "\n",
        "Next up: **building and training models with PyTorch** ðŸš€\n"
      ],
      "metadata": {
        "id": "pdFUQaCgLVjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Linear Regression\n",
        "\n",
        "We will start by implementing linear regression using tensors and autograd directly.\n",
        "Then we will simplify the code using PyTorchâ€™s high-level API and add GPU support.\n"
      ],
      "metadata": {
        "id": "-gIxwXUvLgeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumes the California housing dataset is already loaded and split:\n",
        "# X_train, X_valid, X_test\n",
        "# y_train, y_valid, y_test\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "jK222042Lnot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting the Data to Tensors and Normalizing\n",
        "\n",
        "We convert the NumPy arrays to PyTorch tensors and normalize the input features\n",
        "using tensor operations instead of a StandardScaler.\n"
      ],
      "metadata": {
        "id": "1iA9qyqXLoYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_valid = torch.FloatTensor(X_valid)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "\n",
        "means = X_train.mean(dim=0, keepdims=True)\n",
        "stds = X_train.std(dim=0, keepdims=True)\n",
        "\n",
        "X_train = (X_train - means) / stds\n",
        "X_valid = (X_valid - means) / stds\n",
        "X_test = (X_test - means) / stds\n"
      ],
      "metadata": {
        "id": "m-LrkNkFLpK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the Target Vectors\n",
        "\n",
        "Our predictions will be column vectors, so we reshape the targets\n",
        "to have shape (n_samples, 1).\n"
      ],
      "metadata": {
        "id": "oSo76uBoLqL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.FloatTensor(y_train).reshape(-1, 1)\n",
        "y_valid = torch.FloatTensor(y_valid).reshape(-1, 1)\n",
        "y_test = torch.FloatTensor(y_test).reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "6QAv3tRjLsa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing Model Parameters\n",
        "\n",
        "We initialize the weights randomly and the bias to zero.\n",
        "Random initialization is important to break symmetry.\n"
      ],
      "metadata": {
        "id": "ObudYsbHLtZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "n_features = X_train.shape[1]\n",
        "w = torch.randn((n_features, 1), requires_grad=True)\n",
        "b = torch.tensor(0.0, requires_grad=True)\n"
      ],
      "metadata": {
        "id": "bst-tbBeL9sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Batch Gradient Descent and Autograd\n",
        "\n",
        "We use mean squared error as the loss function and perform batch\n",
        "gradient descent using automatic differentiation.\n"
      ],
      "metadata": {
        "id": "mZBLRzdgL-nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.4\n",
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = X_train @ w + b\n",
        "    loss = ((y_pred - y_train) ** 2).mean()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "hR9dmkB3L_iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions with the Trained Model\n",
        "\n",
        "During inference, we disable gradient tracking using `torch.no_grad()`.\n"
      ],
      "metadata": {
        "id": "-eEg7JF6MAZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[:3]\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = X_new @ w + b\n",
        "\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "NtjTROWjMBSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression Using PyTorchâ€™s High-Level API\n",
        "\n",
        "PyTorch provides the `nn.Linear` module, which greatly simplifies\n",
        "model definition and training.\n"
      ],
      "metadata": {
        "id": "_j0hUvHyMCKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "3Ut7RKfaMC-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Model\n",
        "\n",
        "We create a linear regression model with one output neuron.\n"
      ],
      "metadata": {
        "id": "VtzyMiSbMFHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = nn.Linear(in_features=n_features, out_features=1)\n"
      ],
      "metadata": {
        "id": "HCzUb0K2MGHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting Model Parameters\n",
        "\n",
        "The model automatically creates and initializes weights and bias terms.\n"
      ],
      "metadata": {
        "id": "x0nA4Ru_MG3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.weight, model.bias\n"
      ],
      "metadata": {
        "id": "4uhbCKZcMHtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Optimizer and Loss Function\n",
        "\n",
        "We use stochastic gradient descent (SGD) and mean squared error loss.\n"
      ],
      "metadata": {
        "id": "jX0bj6SjMIfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "3mDEWpB0MJNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop Using the High-Level API\n",
        "\n",
        "The optimizer handles parameter updates and gradient clearing automatically.\n"
      ],
      "metadata": {
        "id": "po2Fi6VzMJ8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
        "    for epoch in range(n_epochs):\n",
        "        y_pred = model(X_train)\n",
        "        loss = criterion(y_pred, y_train)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "6JQ59G-tMK5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n"
      ],
      "metadata": {
        "id": "B0l4u57JMLzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs)\n"
      ],
      "metadata": {
        "id": "uWx3xrnJMMlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions with the High-Level Model\n"
      ],
      "metadata": {
        "id": "Kf7MB3TEMQ52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[:3]\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_new)\n",
        "\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "mqWCjvxaMR1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Regression MLP\n",
        "\n",
        "PyTorch provides the `nn.Sequential` module, which chains multiple modules together.\n",
        "When called, the input is passed through each module in sequence.\n",
        "This makes it ideal for building multilayer perceptrons (MLPs).\n"
      ],
      "metadata": {
        "id": "Xhi0JLFnN4a2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the MLP Architecture\n",
        "\n",
        "We build an MLP with:\n",
        "- Two hidden layers\n",
        "- ReLU activation functions\n",
        "- A single output neuron for regression\n"
      ],
      "metadata": {
        "id": "lUWw_l8aOEP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 1)\n",
        ")\n"
      ],
      "metadata": {
        "id": "SPF4ZpuDOD2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the Model Structure\n",
        "\n",
        "- The first linear layer takes `n_features` inputs and outputs 50 features.\n",
        "- `ReLU` applies a non-linear activation function element-wise.\n",
        "- The second linear layer maps 50 inputs to 40 outputs.\n",
        "- Another `ReLU` introduces non-linearity.\n",
        "- The final linear layer outputs a single value, matching the regression target.\n"
      ],
      "metadata": {
        "id": "dY64cxaxOGxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up the Optimizer and Loss Function\n",
        "\n",
        "We use:\n",
        "- Stochastic Gradient Descent (SGD) as the optimizer\n",
        "- Mean Squared Error (MSE) as the loss function\n"
      ],
      "metadata": {
        "id": "jrWr1Wf9OHdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "mse = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "yPYVaE3-OIVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the MLP Using Batch Gradient Descent\n",
        "\n",
        "We reuse the `train_bgd` function defined earlier.\n"
      ],
      "metadata": {
        "id": "2H4b1d8qOJJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)\n"
      ],
      "metadata": {
        "id": "aOpHFtamPcpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observing Training Progress\n",
        "\n",
        "You should see the loss decrease over epochs, for example:\n",
        "\n",
        "Epoch 1/20, Loss: 5.045  \n",
        "Epoch 2/20, Loss: 2.052  \n",
        "...  \n",
        "Epoch 20/20, Loss: 0.565  \n",
        "\n",
        "This confirms that the neural network is learning.\n"
      ],
      "metadata": {
        "id": "h_gkVdpLPdZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "You have successfully trained a regression MLP using PyTorch.\n",
        "The model can now capture nonlinear relationships in the data.\n",
        "However, we are still using batch gradient descent, which does not scale well.\n"
      ],
      "metadata": {
        "id": "JMNPRcSHPeLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Mini-Batch Gradient Descent Using DataLoaders\n",
        "\n",
        "To efficiently implement mini-batch gradient descent, PyTorch provides the\n",
        "`DataLoader` class in `torch.utils.data`. It loads data in batches, optionally\n",
        "shuffles it at each epoch, and can parallelize data loading.\n"
      ],
      "metadata": {
        "id": "Ic94XwCdP444"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the Dataset\n",
        "\n",
        "The `DataLoader` expects a dataset object implementing:\n",
        "- `__len__()` â†’ number of samples\n",
        "- `__getitem__(index)` â†’ returns one sample and its target\n",
        "\n",
        "PyTorch provides `TensorDataset` to easily wrap tensors.\n"
      ],
      "metadata": {
        "id": "0wvQpG2SP5zO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "bT8NOEhZP6ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Hardware Acceleration (GPU)\n",
        "\n",
        "To leverage a GPU, we must:\n",
        "1. Move the model to the GPU\n",
        "2. Move each mini-batch to the GPU during training\n"
      ],
      "metadata": {
        "id": "jqhYsOhjP7Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 1)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "si3Wjp1hP8B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Optimizer and Loss Function\n",
        "\n",
        "âš ï¸ Important: create the optimizer **after** moving the model to the GPU,\n",
        "since optimizers may store internal state on the same device.\n"
      ],
      "metadata": {
        "id": "ouFsk-8JP8oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.02\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "mse = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "MvgNinblP9cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function with Mini-Batch Gradient Descent\n",
        "\n",
        "This function:\n",
        "- Iterates over epochs\n",
        "- Processes one mini-batch at a time\n",
        "- Accumulates the mean loss per epoch\n",
        "- Uses `model.train()` to enable training mode\n"
      ],
      "metadata": {
        "id": "VeUriWdqP-MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "wingI6jQP_GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\n",
        "\n",
        "We now train the model using mini-batch gradient descent on the GPU.\n"
      ],
      "metadata": {
        "id": "YgJOD-jmQAJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, mse, train_loader, n_epochs)\n"
      ],
      "metadata": {
        "id": "bknbg1-OQAzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observing Training Results\n",
        "\n",
        "Typical output:\n",
        "\n",
        "Epoch 1/20, Loss: 0.6958  \n",
        "Epoch 2/20, Loss: 0.4480  \n",
        "...  \n",
        "Epoch 20/20, Loss: 0.3227  \n",
        "\n",
        "The loss is significantly lower than with batch gradient descent.\n"
      ],
      "metadata": {
        "id": "siPHWSvpQBeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Optimization Tips\n",
        "\n",
        "1. **Pinned Memory (CUDA only)**  \n",
        "   Use `pin_memory=True` in the DataLoader and `non_blocking=True` when calling\n",
        "   `.to(device)` to speed up CPU â†’ GPU transfers.\n",
        "\n",
        "2. **Parallel Data Loading**  \n",
        "   Use `num_workers > 0` to load batches in parallel.\n",
        "   Tune `prefetch_factor` and consider `persistent_workers=True`.\n"
      ],
      "metadata": {
        "id": "lR5FnhnvQCWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "You can now:\n",
        "- Train neural networks using mini-batch gradient descent\n",
        "- Use GPUs efficiently with PyTorch\n",
        "- Scale training to larger datasets and models\n",
        "\n",
        "Next, we will focus on **model evaluation and validation**.\n"
      ],
      "metadata": {
        "id": "v9duc_nDQNyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Letâ€™s write a function to evaluate the model. It takes the model and a `DataLoader` for the dataset that we want to evaluate the model on, as well as a function to compute the metric for a given batch, and lastly a function to aggregate the batch metrics (by default, it just computes the mean).\n"
      ],
      "metadata": {
        "id": "Ar14rPgaQ6Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
        "    model.eval()\n",
        "    metrics = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric = metric_fn(y_pred, y_batch)\n",
        "            metrics.append(metric)\n",
        "    return aggregate_fn(torch.stack(metrics))\n"
      ],
      "metadata": {
        "id": "s2JwnhaIQ8Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now letâ€™s build a `TensorDataset` and a `DataLoader` for our validation set, and pass it to our `evaluate()` function to compute the validation MSE.\n"
      ],
      "metadata": {
        "id": "FMHWfem8RRNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "valid_dataset = TensorDataset(X_valid, y_valid)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
        "\n",
        "valid_mse = evaluate(model, valid_loader, mse)\n",
        "valid_mse\n"
      ],
      "metadata": {
        "id": "K3ojwGTZRSnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works fine. But now suppose we want to use the RMSE instead of the MSE (as we saw in Chapter 2, it can be easier to interpret).\n",
        "\n",
        "PyTorch does not have a built-in function for RMSE, but itâ€™s easy enough to write.\n"
      ],
      "metadata": {
        "id": "fPdT1ItvRTV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_pred, y_true):\n",
        "    return ((y_pred - y_true) ** 2).mean().sqrt()\n",
        "\n",
        "evaluate(model, valid_loader, rmse)\n"
      ],
      "metadata": {
        "id": "NZuCwg6rRUA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But wait a second! The RMSE should be equal to the square root of the MSE. However, when we compute the square root of the MSE that we found earlier, we get a different result.\n"
      ],
      "metadata": {
        "id": "TkFNUqunRU8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_mse.sqrt()\n"
      ],
      "metadata": {
        "id": "k8NuRTgHRV2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason is that instead of calculating the RMSE over the whole validation set, we computed it over each batch and then averaged the batch RMSEs. This is not mathematically equivalent.\n",
        "\n",
        "To solve this, we can use the MSE as our `metric_fn`, and use the `aggregate_fn` to compute the square root of the mean MSE.\n"
      ],
      "metadata": {
        "id": "crMCUg_qRWnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    model,\n",
        "    valid_loader,\n",
        "    mse,\n",
        "    aggregate_fn=lambda metrics: torch.sqrt(torch.mean(metrics))\n",
        ")\n"
      ],
      "metadata": {
        "id": "CsQcJBnlRYEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thatâ€™s much better!\n",
        "\n",
        "Rather than implementing metrics yourself, you may prefer to use the **TorchMetrics** library (made by the same team as PyTorch Lightning), which provides many well-tested streaming metrics.\n",
        "\n",
        "A streaming metric is an object that keeps track of a given metric and can be updated one batch at a time.\n",
        "\n",
        "TorchMetrics is not preinstalled on Colab, so we need to install it first.\n"
      ],
      "metadata": {
        "id": "NPqTs5myRY6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics\n"
      ],
      "metadata": {
        "id": "15DDfEnDRaEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can implement an evaluation function using TorchMetrics.\n"
      ],
      "metadata": {
        "id": "5lkFpvjdRawv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "def evaluate_tm(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric.update(y_pred, y_batch)\n",
        "    return metric.compute()\n"
      ],
      "metadata": {
        "id": "WkmIWiAfRboO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create an RMSE streaming metric, move it to the GPU, and use it to evaluate the validation set.\n"
      ],
      "metadata": {
        "id": "QHkHMo2pRceI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_metric = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
        "\n",
        "evaluate_tm(model, valid_loader, rmse_metric)\n"
      ],
      "metadata": {
        "id": "ST3_liGqRdgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure enough, we get the correct result!\n",
        "\n",
        "Next steps:\n",
        "- Update the `train()` function to evaluate performance during training\n",
        "- Measure metrics on the training set during each epoch\n",
        "- Measure metrics on the validation set at the end of each epoch\n",
        "- Plot learning curves to detect overfitting (using Matplotlib or TensorBoard)\n",
        "\n",
        "Now you know how to build, train, and evaluate a regression MLP using PyTorch, and how to make predictions with a trained model.\n",
        "\n",
        "So far, weâ€™ve only worked with simple sequential models composed of linear layers and ReLU activations. To build more complex, nonsequential models, weâ€™ll need to create **custom PyTorch modules**.\n"
      ],
      "metadata": {
        "id": "0TSYg6LgRgUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Nonsequential Models Using Custom Modules\n",
        "\n",
        "One example of a nonsequential neural network is a **Wide & Deep neural network**. This architecture was introduced in a 2016 paper by Heng-Tze Cheng et al.\n",
        "\n",
        "It connects all or part of the inputs directly to the output layer. This allows the model to learn:\n",
        "- **Deep patterns** via the deep path\n",
        "- **Simple rules** via the wide (shortcut) path\n",
        "\n",
        "The short path can also include manually engineered features. In contrast, a regular MLP forces all data through the full stack of layers, which may distort simple patterns.\n"
      ],
      "metadata": {
        "id": "pX1_hsqaR6Su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wide & Deep Architecture\n",
        "\n",
        "We will build a Wide & Deep neural network for the California housing dataset. Since this architecture is nonsequential, we must create a **custom PyTorch module**.\n"
      ],
      "metadata": {
        "id": "VdLLad3mR8HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "PP1eZrulR8x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeep(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 40),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(40 + n_features, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        deep_output = self.deep_stack(X)\n",
        "        wide_and_deep = torch.concat([X, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)\n"
      ],
      "metadata": {
        "id": "01dOQ7L_R9mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation\n",
        "\n",
        "- We use `nn.Sequential` to build the deep part of the model.\n",
        "- The output layer receives the concatenation of:\n",
        "  - the original inputs (wide path)\n",
        "  - the deep stackâ€™s output (deep path)\n",
        "- Therefore, the output layer has `40 + n_features` inputs.\n"
      ],
      "metadata": {
        "id": "SGDZmTDhR-eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and Using the Model\n"
      ],
      "metadata": {
        "id": "VW9kK_geR_Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = WideAndDeep(n_features).to(device)\n",
        "learning_rate = 0.002  # adjusted for the new architecture\n",
        "\n",
        "# Train, evaluate, and use the model exactly like before\n"
      ],
      "metadata": {
        "id": "n3T0yeSoR__C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Features Inside the Model\n",
        "\n",
        "Sometimes we want only **part of the features** to go through the wide path and a (possibly overlapping) subset to go through the deep path.\n"
      ],
      "metadata": {
        "id": "Xd_lY5RASAzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeepV2(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 40),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(40 + 5, 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_wide = X[:, :5]\n",
        "        X_deep = X[:, 2:]\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)\n"
      ],
      "metadata": {
        "id": "JBgMDzF1SBj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Models with Multiple Inputs\n",
        "\n",
        "Some models require multiple inputs that cannot be combined into a single tensor (e.g., images + text).\n",
        "\n",
        "To support this, we modify the `forward()` method to accept multiple tensors.\n"
      ],
      "metadata": {
        "id": "_WQKHi0nSCdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeepV3(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 40),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(40 + 5, 1)\n",
        "\n",
        "    def forward(self, X_wide, X_deep):\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        return self.output_layer(wide_and_deep)\n"
      ],
      "metadata": {
        "id": "zKR3UOBOSDVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Data for Multiple Inputs\n"
      ],
      "metadata": {
        "id": "2LtQPXqLSEUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_data_wd = TensorDataset(\n",
        "    X_train[:, :5],\n",
        "    X_train[:, 2:],\n",
        "    y_train\n",
        ")\n",
        "\n",
        "train_loader_wd = DataLoader(train_data_wd, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "D2zGd6JaSFAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updating the Training / Evaluation Loop\n"
      ],
      "metadata": {
        "id": "FkBESptKSFs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for X_batch_wide, X_batch_deep, y_batch in train_loader_wd:\n",
        "    X_batch_wide = X_batch_wide.to(device)\n",
        "    X_batch_deep = X_batch_deep.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    y_pred = model(X_batch_wide, X_batch_deep)\n"
      ],
      "metadata": {
        "id": "tYRKwwB3SHed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flexible Input Handling with `*` Unpacking\n"
      ],
      "metadata": {
        "id": "ZEKy-Dq2SIMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for *X_batch_inputs, y_batch in train_loader_wd:\n",
        "    X_batch_inputs = [X.to(device) for X in X_batch_inputs]\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    y_pred = model(*X_batch_inputs)\n"
      ],
      "metadata": {
        "id": "c6rTrPKUSI_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for *X_batch_inputs, y_batch in train_loader_wd:\n",
        "    X_batch_inputs = [X.to(device) for X in X_batch_inputs]\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    y_pred = model(*X_batch_inputs)\n"
      ],
      "metadata": {
        "id": "IAc7BD4ASJsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeepDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X_wide, X_deep, y):\n",
        "        self.X_wide = X_wide\n",
        "        self.X_deep = X_deep\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = {\n",
        "            \"X_wide\": self.X_wide[idx],\n",
        "            \"X_deep\": self.X_deep[idx]\n",
        "        }\n",
        "        return inputs, self.y[idx]\n"
      ],
      "metadata": {
        "id": "27au7oTVSKqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_named = WideAndDeepDataset(\n",
        "    X_wide=X_train[:, :5],\n",
        "    X_deep=X_train[:, 2:],\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "train_loader_named = DataLoader(\n",
        "    train_data_named,\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "VRL0Xr-NSLpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Named Inputs\n"
      ],
      "metadata": {
        "id": "6zFDPUknSM_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, y_batch in train_loader_named:\n",
        "    inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    y_pred = model(**inputs)\n"
      ],
      "metadata": {
        "id": "g5_t3cSFSO8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Models with Multiple Outputs\n",
        "\n",
        "Multiple outputs are useful for:\n",
        "- Multitask learning\n",
        "- Combining regression and classification\n",
        "- Regularization via auxiliary outputs\n"
      ],
      "metadata": {
        "id": "bUgt-VzuSPxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeepV4(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super().__init__()\n",
        "        self.deep_stack = nn.Sequential(\n",
        "            nn.Linear(n_features - 2, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 40),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Linear(40 + 5, 1)\n",
        "        self.aux_output_layer = nn.Linear(40, 1)\n",
        "\n",
        "    def forward(self, X_wide, X_deep):\n",
        "        deep_output = self.deep_stack(X_deep)\n",
        "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
        "        main_output = self.output_layer(wide_and_deep)\n",
        "        aux_output = self.aux_output_layer(deep_output)\n",
        "        return main_output, aux_output\n"
      ],
      "metadata": {
        "id": "QBZwRGSESQno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with an Auxiliary Loss\n"
      ],
      "metadata": {
        "id": "feNrFllTSRdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, y_batch in train_loader_named:\n",
        "    inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    y_pred, y_pred_aux = model(**inputs)\n",
        "\n",
        "    main_loss = criterion(y_pred, y_batch)\n",
        "    aux_loss = criterion(y_pred_aux, y_batch)\n",
        "\n",
        "    loss = 0.8 * main_loss + 0.2 * aux_loss\n"
      ],
      "metadata": {
        "id": "7tN2M3ueSSNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation (Ignoring Auxiliary Output)\n"
      ],
      "metadata": {
        "id": "b4iWBxOwSTFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, y_batch in train_loader_named:\n",
        "    inputs = {name: X.to(device) for name, X in inputs.items()}\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    y_pred, _ = model(**inputs)\n"
      ],
      "metadata": {
        "id": "_OyQeTlvST74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "You now know how to:\n",
        "- Build **sequential and nonsequential** models\n",
        "- Handle **multiple inputs**\n",
        "- Handle **multiple outputs**\n",
        "- Use **auxiliary losses for regularization**\n",
        "\n",
        "Next up: **classification models** ðŸš€\n"
      ],
      "metadata": {
        "id": "7vBvZiudSVMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building an Image Classifier with PyTorch\n",
        "\n",
        "As in Chapter 9, we will tackle the **Fashion MNIST** dataset. This time, instead of using `fetch_openml()`, we will load the dataset using the **TorchVision** library.\n"
      ],
      "metadata": {
        "id": "tKHIvNI2SvY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using TorchVision to Load the Dataset\n",
        "\n",
        "TorchVision is an important part of the PyTorch ecosystem. It provides:\n",
        "- Utility functions to download common datasets (MNIST, Fashion MNIST, etc.)\n",
        "- Pretrained models\n",
        "- Image transformation utilities (crop, resize, rotate, etc.)\n",
        "\n",
        "TorchVision is preinstalled on Colab.\n"
      ],
      "metadata": {
        "id": "fI8YG3qiSwEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as T\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "N-WFu-YqSxXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Image Transform\n",
        "\n",
        "By default, FashionMNIST images are loaded as PIL images with pixel values from 0 to 255.\n",
        "We need:\n",
        "- PyTorch tensors\n",
        "- `float32` values\n",
        "- Pixel values scaled to `[0.0, 1.0]`\n"
      ],
      "metadata": {
        "id": "ivAIGlQ5Syqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toTensor = T.Compose([\n",
        "    T.ToImage(),\n",
        "    T.ToDtype(torch.float32, scale=True)\n",
        "])\n"
      ],
      "metadata": {
        "id": "jHqLJKWuSzlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset\n",
        "\n",
        "The dataset is already split into:\n",
        "- 60,000 training images\n",
        "- 10,000 test images\n",
        "\n",
        "We will further split the training set into:\n",
        "- 55,000 training images\n",
        "- 5,000 validation images\n"
      ],
      "metadata": {
        "id": "_L0E06EeS0PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=toTensor\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=toTensor\n",
        ")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_data, valid_data = torch.utils.data.random_split(\n",
        "    train_and_valid_data, [55_000, 5_000]\n",
        ")\n"
      ],
      "metadata": {
        "id": "-Ur-1mj5S1Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating DataLoaders\n"
      ],
      "metadata": {
        "id": "jIgHkcmMS19w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)\n"
      ],
      "metadata": {
        "id": "Yap1uS6PS20c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting the Data\n"
      ],
      "metadata": {
        "id": "eJiDb4pFS4VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample, y_sample = train_data[0]\n",
        "\n",
        "X_sample.shape, X_sample.dtype\n"
      ],
      "metadata": {
        "id": "drEOp7WxS5WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image has shape:\n",
        "\n",
        "- `[1, 28, 28]`\n",
        "  - 1 channel (grayscale)\n",
        "  - 28 Ã— 28 pixels\n",
        "\n",
        "PyTorch expects the **channel dimension first**, unlike many other libraries.\n"
      ],
      "metadata": {
        "id": "LSn_lIQUS6Ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting the Label\n"
      ],
      "metadata": {
        "id": "xT7oo00VS7MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_valid_data.classes[y_sample]\n"
      ],
      "metadata": {
        "id": "hUEq-ILOS74q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Classifier\n",
        "\n",
        "We will build a **classification MLP** with:\n",
        "- Two hidden layers\n",
        "- ReLU activations\n",
        "- A linear output layer with 10 outputs (one per class)\n"
      ],
      "metadata": {
        "id": "4glIjX-YTIoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "xy9x0SwaU57b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(n_inputs, n_hidden1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden1, n_hidden2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden2, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.mlp(X)\n"
      ],
      "metadata": {
        "id": "iJ_UThttU6pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Model and Loss Function\n"
      ],
      "metadata": {
        "id": "lmbABPQ2U7zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = ImageClassifier(\n",
        "    n_inputs=28 * 28,\n",
        "    n_hidden1=300,\n",
        "    n_hidden2=100,\n",
        "    n_classes=10\n",
        ")\n",
        "\n",
        "xentropy = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "Wjh0pYWeU8rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Notes\n",
        "\n",
        "- `nn.Flatten()` reshapes images from `[batch, 1, 28, 28]` to `[batch, 784]`\n",
        "- No activation function is used after the output layer\n",
        "- `nn.CrossEntropyLoss` expects **raw logits**, not probabilities\n"
      ],
      "metadata": {
        "id": "q8Ba2vepU9aX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "We can train the model using the same `train()` function as before.\n",
        "For evaluation, we use the **Accuracy** streaming metric from TorchMetrics.\n"
      ],
      "metadata": {
        "id": "OHO6xjCBU-dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "accuracy = torchmetrics.Accuracy(\n",
        "    task=\"multiclass\",\n",
        "    num_classes=10\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "u0j7oTvZU_Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âš ï¸ Training will take a few minutes on GPU (much longer on CPU).\n",
        "\n",
        "Typical results:\n",
        "- Training accuracy â‰ˆ **92.8%**\n",
        "- Validation accuracy â‰ˆ **87.2%**\n",
        "\n",
        "This indicates slight overfitting.\n"
      ],
      "metadata": {
        "id": "NUyucq4lVAGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions\n"
      ],
      "metadata": {
        "id": "KBM5BPtfVAw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "X_new, y_new = next(iter(valid_loader))\n",
        "X_new = X_new[:3].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred_logits = model(X_new)\n",
        "\n",
        "y_pred = y_pred_logits.argmax(dim=1)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "MOG3OrOnVBhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicted Class Names\n"
      ],
      "metadata": {
        "id": "8-1lltLjVCje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[train_and_valid_data.classes[index] for index in y_pred]\n"
      ],
      "metadata": {
        "id": "TwYyWwwpVE36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Class Probabilities with Softmax\n"
      ],
      "metadata": {
        "id": "wEPUSkAbVFuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y_proba = F.softmax(y_pred_logits, dim=1)\n",
        "y_proba.round(decimals=3)\n"
      ],
      "metadata": {
        "id": "ZmRias8OVGh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top-K Predictions\n"
      ],
      "metadata": {
        "id": "OIvWU87TVHhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_top4_logits, y_top4_indices = torch.topk(\n",
        "    y_pred_logits, k=4, dim=1\n",
        ")\n",
        "\n",
        "y_top4_probas = F.softmax(y_top4_logits, dim=1)\n",
        "y_top4_probas.round(decimals=3), y_top4_indices\n"
      ],
      "metadata": {
        "id": "cw3hOvuXVIQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation\n",
        "\n",
        "For each image:\n",
        "- The modelâ€™s prediction is the class with the highest logit\n",
        "- Top-K predictions show alternative plausible classes and confidence levels\n"
      ],
      "metadata": {
        "id": "4ylOiu2IVKey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Class Imbalance\n",
        "\n",
        "Fashion MNIST is balanced, but for imbalanced datasets, you should weight classes using the `weight` argument of `nn.CrossEntropyLoss`.\n"
      ],
      "metadata": {
        "id": "nRxrLc5zVLVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "You can now:\n",
        "- Load image datasets using TorchVision\n",
        "- Build image classifiers in PyTorch\n",
        "- Train and evaluate multiclass models\n",
        "- Compute probabilities and top-K predictions\n",
        "\n",
        "Next up: **hyperparameter tuning** ðŸš€\n"
      ],
      "metadata": {
        "id": "6s_t9KvwVMBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Neural Network Hyperparameters with Optuna\n",
        "\n",
        "So far, we have manually chosen reasonable values for our modelâ€™s hyperparameters. However, manual tuning can be slow and suboptimal. A better approach is to use an automated hyperparameter optimization library.\n",
        "\n",
        "Popular libraries for this include:\n",
        "- **Optuna**\n",
        "- Ray Tune\n",
        "- Hyperopt\n",
        "\n",
        "In this section, we will use **Optuna**, a powerful and flexible hyperparameter optimization framework.\n",
        "\n",
        "Optuna is not preinstalled on Google Colab, so we must install it first.\n"
      ],
      "metadata": {
        "id": "a0xqODURWEck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install optuna\n"
      ],
      "metadata": {
        "id": "wby4Tqf2WGRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Objective Function\n",
        "\n",
        "Optuna works by repeatedly calling an **objective function**. This function:\n",
        "1. Receives a `Trial` object\n",
        "2. Uses it to sample hyperparameter values\n",
        "3. Builds and trains a model using those values\n",
        "4. Evaluates the model on the validation set\n",
        "5. Returns a metric (higher is better in our case)\n",
        "\n",
        "We will tune:\n",
        "- The **learning rate**\n",
        "- The **number of neurons** in the hidden layers (same size for both layers)\n"
      ],
      "metadata": {
        "id": "l5RPB-ZMWHQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    learning_rate = trial.suggest_float(\n",
        "        \"learning_rate\", 1e-5, 1e-1, log=True\n",
        "    )\n",
        "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
        "\n",
        "    # Build model\n",
        "    model = ImageClassifier(\n",
        "        n_inputs=28 * 28,\n",
        "        n_hidden1=n_hidden,\n",
        "        n_hidden2=n_hidden,\n",
        "        n_classes=10\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop (simplified)\n",
        "    n_epochs = 5\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            logits = model(X_batch)\n",
        "            loss = loss_fn(logits, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in valid_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            logits = model(X_batch)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    validation_accuracy = correct / total\n",
        "    return validation_accuracy\n"
      ],
      "metadata": {
        "id": "QE07TfrqWIJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Hyperparameter Search\n",
        "\n",
        "To start optimization, we create a **Study** object. Since we want to maximize validation accuracy, we set `direction=\"maximize\"`.\n",
        "\n",
        "We also:\n",
        "- Fix PyTorchâ€™s random seed\n",
        "- Use Optunaâ€™s **TPE sampler** for smarter search\n"
      ],
      "metadata": {
        "id": "CEL9hqpgWJ5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    sampler=sampler\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=5)\n"
      ],
      "metadata": {
        "id": "Yi_BmRGlWKt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optuna uses the **Tree-structured Parzen Estimator (TPE)** algorithm.\n",
        "\n",
        "This is a sequential, model-based optimization strategy:\n",
        "- Early trials are mostly random\n",
        "- Later trials focus on promising regions of the search space\n",
        "\n",
        "This usually finds better hyperparameters than random search in the same amount of time.\n"
      ],
      "metadata": {
        "id": "Dzp3CQ_wWLVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params, study.best_value\n"
      ],
      "metadata": {
        "id": "dLLgCUUcWMMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shows:\n",
        "- The best learning rate\n",
        "- The best number of hidden neurons\n",
        "- The corresponding validation accuracy\n",
        "\n",
        "Increasing `n_trials` (e.g., to 50 or more) will usually improve results, but at the cost of much longer runtimes.\n"
      ],
      "metadata": {
        "id": "iV_NORlBWM3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passing Data Explicitly to the Objective Function\n",
        "\n",
        "Rather than relying on global variables, it is cleaner to pass the data loaders explicitly.\n",
        "\n",
        "One way is to use a `lambda` function.\n"
      ],
      "metadata": {
        "id": "olh4UP5hWNyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "objective_with_data = lambda trial: objective(trial)\n",
        "\n",
        "study.optimize(objective_with_data, n_trials=5)\n"
      ],
      "metadata": {
        "id": "IE22JSkUWOfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another cleaner option is to use `functools.partial`, which creates a wrapped function with fixed arguments.\n"
      ],
      "metadata": {
        "id": "NwKRRcGtWPbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "objective_with_data = partial(objective)\n",
        "study.optimize(objective_with_data, n_trials=5)\n"
      ],
      "metadata": {
        "id": "JtnlRMGmWQFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning Bad Trials Early\n",
        "\n",
        "Some hyperparameter combinations are obviously bad:\n",
        "- Loss explodes early\n",
        "- Accuracy barely improves\n",
        "\n",
        "To avoid wasting compute, Optuna supports **trial pruning**.\n",
        "\n",
        "We will use the `MedianPruner`, which:\n",
        "- Compares each trialâ€™s performance to the median of past trials\n",
        "- Stops trials that perform significantly worse\n"
      ],
      "metadata": {
        "id": "f-B7U0R2WQy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruner = optuna.pruners.MedianPruner(\n",
        "    n_startup_trials=5,\n",
        "    n_warmup_steps=0,\n",
        "    interval_steps=1\n",
        ")\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    sampler=sampler,\n",
        "    pruner=pruner\n",
        ")\n"
      ],
      "metadata": {
        "id": "-IVUAgTIWR2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside the objective function, we must report progress after each epoch and allow pruning.\n"
      ],
      "metadata": {
        "id": "FXwnwDS1WSdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    # Train for one epoch\n",
        "    ...\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    validation_accuracy = ...\n",
        "\n",
        "    trial.report(validation_accuracy, epoch)\n",
        "\n",
        "    if trial.should_prune():\n",
        "        raise optuna.TrialPruned()\n"
      ],
      "metadata": {
        "id": "fpVA25_PWTgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Notes\n",
        "\n",
        "Once you find good hyperparameters:\n",
        "1. Retrain the model on the **full training set**\n",
        "2. Evaluate on the **test set**\n",
        "3. Save the trained model\n",
        "4. Load it later for inference or production use\n",
        "\n",
        "At this point, you have full control over:\n",
        "- Model architecture\n",
        "- Training loop\n",
        "- Automated hyperparameter optimization\n",
        "\n",
        "ðŸ”¥ Your PyTorch skills are officially getting serious.\n"
      ],
      "metadata": {
        "id": "nxJ7V3KpWURW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading PyTorch Models\n",
        "\n",
        "The simplest way to save a PyTorch model is to use `torch.save()`, passing the model and a file path.\n",
        "\n",
        "PyTorch uses Pythonâ€™s `pickle` module internally to serialize the object, then compresses it before saving. By convention, PyTorch model files use the `.pt` or `.pth` extension.\n"
      ],
      "metadata": {
        "id": "CkbAwqx3YtgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"my_fashion_mnist.pt\")\n"
      ],
      "metadata": {
        "id": "KnDbW2pjYuYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Entire Model\n",
        "\n",
        "Loading the model back is just as simple. By setting `weights_only=False`, PyTorch loads the entire model object, not just its parameters.\n"
      ],
      "metadata": {
        "id": "AoPZoso_Yvhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = torch.load(\"my_fashion_mnist.pt\", weights_only=False)\n"
      ],
      "metadata": {
        "id": "eED49NfRYwV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before using the loaded model for inference, remember to switch it to evaluation mode.\n"
      ],
      "metadata": {
        "id": "hR8kxc7HYxED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.eval()\n",
        "y_pred_logits = loaded_model(X_new)\n"
      ],
      "metadata": {
        "id": "Jq8mPUjhYx6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš ï¸ Important Warnings About Saving Full Models\n",
        "\n",
        "Saving the entire model using `torch.save(model, ...)` has **serious drawbacks**:\n",
        "\n",
        "1. **Security risk**  \n",
        "   The `pickle` format can execute arbitrary code during loading. Never load a model file from an untrusted source.\n",
        "\n",
        "2. **Fragility**  \n",
        "   Pickle depends on:\n",
        "   - Python version\n",
        "   - File paths\n",
        "   - Exact code structure\n",
        "\n",
        "   Even small changes can break loading.\n",
        "\n",
        "Because of these issues, **saving only the model weights is strongly recommended**.\n"
      ],
      "metadata": {
        "id": "VZVeqZRiYy13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model Weights Only (Recommended)\n",
        "\n",
        "Instead of saving the full model, we save its **state dictionary** using `state_dict()`.\n",
        "\n",
        "This dictionary contains:\n",
        "- All model parameters\n",
        "- Any registered buffers (non-trainable tensors)\n",
        "\n",
        "This approach is safer and more robust.\n"
      ],
      "metadata": {
        "id": "LAchOD9EYz_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"my_fashion_mnist_weights.pt\")\n"
      ],
      "metadata": {
        "id": "Q7puNeFbY0sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model Weights\n",
        "\n",
        "To load the saved weights:\n",
        "1. Recreate the model with the **exact same architecture**\n",
        "2. Load the weights using `load_state_dict()`\n",
        "3. Switch the model to evaluation mode\n"
      ],
      "metadata": {
        "id": "GBABatOAY2lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = ImageClassifier(\n",
        "    n_inputs=28 * 28,\n",
        "    n_hidden1=300,\n",
        "    n_hidden2=100,\n",
        "    n_classes=10\n",
        ")\n",
        "\n",
        "loaded_weights = torch.load(\n",
        "    \"my_fashion_mnist_weights.pt\",\n",
        "    weights_only=True\n",
        ")\n",
        "\n",
        "new_model.load_state_dict(loaded_weights)\n",
        "new_model.eval()\n"
      ],
      "metadata": {
        "id": "w0JBZEgRZhk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This approach is:\n",
        "- âœ… Secure (data only, no executable code)\n",
        "- âœ… More stable across Python versions\n",
        "- âœ… Preferred for deployment\n",
        "\n",
        "However, it requires knowing the exact model architecture ahead of time.\n"
      ],
      "metadata": {
        "id": "QHoYfZbUZiMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Weights + Hyperparameters Together\n",
        "\n",
        "To make model reconstruction easier, itâ€™s a good idea to save:\n",
        "- The modelâ€™s weights\n",
        "- The modelâ€™s hyperparameters\n",
        "\n",
        "We can store everything in a single dictionary.\n"
      ],
      "metadata": {
        "id": "JXQ4g_0VZjAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_data = {\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"model_hyperparameters\": {\n",
        "        \"n_inputs\": 28 * 28,\n",
        "        \"n_hidden1\": 300,\n",
        "        \"n_hidden2\": 100,\n",
        "        \"n_classes\": 10\n",
        "    }\n",
        "}\n",
        "\n",
        "torch.save(model_data, \"my_fashion_mnist_model.pt\")\n"
      ],
      "metadata": {
        "id": "8FMFsrj-Zj8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a Model from Saved Metadata\n",
        "\n",
        "We can now:\n",
        "1. Load the dictionary\n",
        "2. Rebuild the model using the saved hyperparameters\n",
        "3. Load the state dictionary\n"
      ],
      "metadata": {
        "id": "X5JP4P5DZkp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_data = torch.load(\n",
        "    \"my_fashion_mnist_model.pt\",\n",
        "    weights_only=True\n",
        ")\n",
        "\n",
        "new_model = ImageClassifier(\n",
        "    **loaded_data[\"model_hyperparameters\"]\n",
        ")\n",
        "\n",
        "new_model.load_state_dict(loaded_data[\"model_state_dict\"])\n",
        "new_model.eval()\n"
      ],
      "metadata": {
        "id": "r-4sfg3ZZltc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resuming Training\n",
        "\n",
        "If you want to continue training later, you should also save:\n",
        "- The optimizerâ€™s `state_dict()`\n",
        "- Optimizer hyperparameters\n",
        "- Current epoch number\n",
        "- Training/validation loss history\n",
        "\n",
        "This allows you to resume training exactly where you left off.\n"
      ],
      "metadata": {
        "id": "scPwaYCeZmcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative: SafeTensors\n",
        "\n",
        "The **SafeTensors** library (by Hugging Face) is another popular and secure way to store model weights. It avoids pickle entirely and is designed specifically for ML models.\n"
      ],
      "metadata": {
        "id": "hcDSTkwgZnPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TorchScript (Preview)\n",
        "\n",
        "Another way to save a PyTorch model is by converting it to **TorchScript**.\n",
        "\n",
        "Benefits:\n",
        "- Faster inference\n",
        "- Language-agnostic deployment\n",
        "- No Python dependency at runtime\n",
        "\n",
        "Weâ€™ll explore TorchScript next.\n"
      ],
      "metadata": {
        "id": "R-q1xnrpZoCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling and Optimizing a PyTorch Model\n",
        "\n",
        "PyTorch provides powerful tools to **compile and optimize models** for faster inference and easier deployment.\n",
        "\n",
        "One major option is **TorchScript**, which converts your model into a statically-typed subset of Python.\n"
      ],
      "metadata": {
        "id": "51CHfsBxbDwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Use TorchScript?\n",
        "\n",
        "TorchScript offers two main benefits:\n",
        "\n",
        "1. **Performance optimizations**\n",
        "   - Operator fusion\n",
        "   - Constant folding (e.g., `2 * 3 â†’ 6`)\n",
        "   - Dead code elimination\n",
        "\n",
        "2. **Deployment flexibility**\n",
        "   - Models can be saved and run without Python\n",
        "   - Can be executed in C++ using LibTorch\n",
        "   - Useful for embedded and production environments\n"
      ],
      "metadata": {
        "id": "uStF1bv1bFG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting a Model to TorchScript: Tracing\n",
        "\n",
        "Tracing runs the model once using example inputs and records all operations that occur.\n"
      ],
      "metadata": {
        "id": "pa-rbn_2bF88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchscript_model = torch.jit.trace(model, X_new)\n"
      ],
      "metadata": {
        "id": "qGCvNHVybGqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations of Tracing\n",
        "\n",
        "Tracing works well for **static models**, but it has important limitations:\n",
        "\n",
        "- `if` or `match` statements:\n",
        "  - Only the executed branch is recorded\n",
        "- Loops:\n",
        "  - Only the observed number of iterations is captured\n",
        "\n",
        "This makes tracing unsuitable for dynamic control flow.\n"
      ],
      "metadata": {
        "id": "-VDLue-obIBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting a Model to TorchScript: Scripting\n",
        "\n",
        "Scripting parses the Python source code directly and converts it into TorchScript.\n"
      ],
      "metadata": {
        "id": "oMONnI02bIyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchscript_model = torch.jit.script(model)\n"
      ],
      "metadata": {
        "id": "B6aMXoc1bJuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What Scripting Supports\n",
        "\n",
        "- `if` and `while` statements (tensor-based conditions)\n",
        "- `for` loops over tensors\n",
        "- Proper handling of dynamic control flow\n",
        "\n",
        "### TorchScript Restrictions\n",
        "\n",
        "- No global variables\n",
        "- No generators (`yield`)\n",
        "- No `*args` or `**kwargs`\n",
        "- No match statements\n",
        "- Fixed return types\n",
        "- Only TorchScript-compatible functions allowed\n",
        "\n",
        "Despite these constraints, most real-world models can be scripted without much trouble.\n"
      ],
      "metadata": {
        "id": "vF0Cm8MvbKjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing a TorchScript Model\n",
        "\n",
        "Once converted to TorchScript (via tracing or scripting), the model can be optimized for inference.\n"
      ],
      "metadata": {
        "id": "ddmktbZWbQVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_model = torch.jit.optimize_for_inference(torchscript_model)\n"
      ],
      "metadata": {
        "id": "YXp8x7TwbaH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Note\n",
        "\n",
        "TorchScript models:\n",
        "- âœ… Can be used for inference\n",
        "- âŒ Cannot be trained\n",
        "- âŒ Do not support autograd\n"
      ],
      "metadata": {
        "id": "Ll6mc6m2bbyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and Loading a TorchScript Model\n",
        "\n",
        "TorchScript models have their own `save()` and `load()` APIs.\n"
      ],
      "metadata": {
        "id": "Ru7vJl9QbgYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchscript_model.save(\"my_fashion_mnist_torchscript.pt\")\n"
      ],
      "metadata": {
        "id": "8bn9V0qwbfOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_torchscript_model = torch.jit.load(\n",
        "    \"my_fashion_mnist_torchscript.pt\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "z1M0H0WzbhZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TorchScript Status\n",
        "\n",
        "TorchScript is no longer under active feature development.\n",
        "- Bug fixes only\n",
        "- Still widely used for C++ deployment\n",
        "- Still fully supported\n"
      ],
      "metadata": {
        "id": "2KqvBfz8bi6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch 2.x: torch.compile()\n",
        "\n",
        "Since PyTorch 2.0, the recommended way to optimize models is `torch.compile()`.\n",
        "\n",
        "This provides **Just-In-Time (JIT) compilation** with minimal code changes.\n"
      ],
      "metadata": {
        "id": "iYL7RBR2bkCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_model = torch.compile(model)\n"
      ],
      "metadata": {
        "id": "sjtm91ZcblSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How `torch.compile()` Works\n",
        "\n",
        "- Uses **TorchDynamo** to capture Python bytecode\n",
        "- Handles conditionals and loops correctly\n",
        "- Captures dynamic runtime information\n",
        "\n",
        "By default, it uses **TorchInductor** to:\n",
        "- Generate optimized GPU kernels (via Triton, NVIDIA GPUs)\n",
        "- Optimize CPU execution (via OpenMP)\n",
        "\n",
        "Other backends are available, including XLA for TPUs.\n"
      ],
      "metadata": {
        "id": "JLZHqOAlb1Za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a Different Backend (Example: TPU)\n",
        "\n",
        "To use a different compilation backend, specify the device:\n"
      ],
      "metadata": {
        "id": "o6qD0j8Ub4Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_model = torch.compile(model, device=\"xla\")\n"
      ],
      "metadata": {
        "id": "ukxC4C1Mb5Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "You now know how to:\n",
        "\n",
        "- Convert models to TorchScript (tracing & scripting)\n",
        "- Optimize TorchScript models for inference\n",
        "- Save and load TorchScript models\n",
        "- Use `torch.compile()` for modern PyTorch optimization\n",
        "\n",
        "These tools allow you to build **faster**, **portable**, and **production-ready** PyTorch models.\n"
      ],
      "metadata": {
        "id": "_bMKWiqrb5xn"
      }
    }
  ]
}