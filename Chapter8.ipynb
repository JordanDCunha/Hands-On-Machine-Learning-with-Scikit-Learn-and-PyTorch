{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvumFxe2RWV9gbBqqtAD48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanDCunha/Hands-On-Machine-Learning-with-Scikit-Learn-and-PyTorch/blob/main/Chapter8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering Algorithms: k-Means and DBSCAN\n",
        "\n",
        "Clustering is an **unsupervised learning** task where the goal is to group similar instances together **without labels**.\n",
        "\n",
        "Unlike classification, clustering algorithms must discover structure in the data on their own.\n",
        "\n",
        "Clustering is widely used in:\n",
        "- Customer segmentation\n",
        "- Data analysis\n",
        "- Dimensionality reduction\n",
        "- Feature engineering\n",
        "- Anomaly detection\n",
        "- Semi-supervised learning\n",
        "- Image segmentation\n",
        "\n",
        "There is no single definition of a “cluster.” Some algorithms look for:\n",
        "- Centroid-based clusters\n",
        "- Density-based clusters\n",
        "- Hierarchical clusters\n",
        "\n",
        "In this section, we focus on **k-means clustering**.\n"
      ],
      "metadata": {
        "id": "TgEkHgiRGVrH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1wC0cmNCxhb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate synthetic dataset with 5 clusters\n",
        "X, y = make_blobs(\n",
        "    n_samples=1000,\n",
        "    centers=5,\n",
        "    cluster_std=0.6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], s=10)\n",
        "plt.title(\"Unlabeled Dataset with 5 Blobs\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-Means Clustering\n",
        "\n",
        "k-means is a **centroid-based clustering algorithm**.\n",
        "\n",
        "It works by:\n",
        "1. Randomly initializing `k` centroids\n",
        "2. Assigning each instance to the nearest centroid\n",
        "3. Updating centroids to be the mean of assigned points\n",
        "4. Repeating until centroids stop moving\n",
        "\n",
        "The value of `k` **must be specified in advance**.\n"
      ],
      "metadata": {
        "id": "ussj6yEnGYGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k = 5\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "\n",
        "y_pred = kmeans.fit_predict(X)\n"
      ],
      "metadata": {
        "id": "2ClDokWRGZFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cluster Labels vs Class Labels\n",
        "\n",
        "In clustering:\n",
        "- Labels are **discovered**, not provided\n",
        "- A label is simply a **cluster index**\n",
        "- Labels have no inherent meaning like class labels\n",
        "\n",
        "The labels assigned during training are stored in `labels_`.\n"
      ],
      "metadata": {
        "id": "W5mNnU8eGZ_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First 10 predicted cluster labels\n",
        "y_pred[:10]\n"
      ],
      "metadata": {
        "id": "f4WdraS6GavF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Centroids found by k-means\n",
        "kmeans.cluster_centers_\n"
      ],
      "metadata": {
        "id": "LbQUk68MGbtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing k-Means Clusters\n",
        "\n",
        "k-means partitions space into **Voronoi regions**, where each point belongs to the nearest centroid.\n",
        "\n",
        "It works best when clusters are:\n",
        "- Spherical\n",
        "- Similar in size\n",
        "- Well separated\n"
      ],
      "metadata": {
        "id": "30a7Q1K0GcZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=\"viridis\", s=10)\n",
        "plt.scatter(\n",
        "    kmeans.cluster_centers_[:, 0],\n",
        "    kmeans.cluster_centers_[:, 1],\n",
        "    c=\"red\",\n",
        "    marker=\"x\",\n",
        "    s=100\n",
        ")\n",
        "plt.title(\"k-Means Clustering Result\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sTwuYQD2GdSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assigning New Instances to Clusters\n",
        "\n",
        "Once trained, k-means can assign **new data points** to the nearest centroid.\n"
      ],
      "metadata": {
        "id": "NSVO5dvBGeTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_new = np.array([\n",
        "    [0, 2],\n",
        "    [3, 2],\n",
        "    [-3, 3],\n",
        "    [-3, 2.5]\n",
        "])\n",
        "\n",
        "kmeans.predict(X_new)\n"
      ],
      "metadata": {
        "id": "XNgICqb-Ge-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hard vs Soft Clustering\n",
        "\n",
        "- **Hard clustering**: each instance belongs to exactly one cluster\n",
        "- **Soft clustering**: each instance has a score for every cluster\n",
        "\n",
        "k-means supports soft clustering by measuring distances to centroids.\n"
      ],
      "metadata": {
        "id": "kma-iwcDGf3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance from each instance to each centroid\n",
        "kmeans.transform(X_new).round(2)\n"
      ],
      "metadata": {
        "id": "vHiQ6YW-GhLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This transformation produces a **k-dimensional representation**, which can be used for:\n",
        "- Nonlinear dimensionality reduction\n",
        "- Feature engineering\n",
        "- Feeding into another ML model\n"
      ],
      "metadata": {
        "id": "m9BUQ_PdGhyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The k-Means Algorithm (Summary)\n",
        "\n",
        "The algorithm alternates between:\n",
        "- Assigning instances to the closest centroid\n",
        "- Updating centroids to the mean of assigned points\n",
        "\n",
        "The algorithm is guaranteed to converge because the total squared distance to centroids always decreases.\n",
        "\n",
        "However, it may converge to a **local optimum**, depending on centroid initialization.\n"
      ],
      "metadata": {
        "id": "WvFE_MxPGin3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Strengths and Limitations of k-Means\n",
        "\n",
        "### Strengths\n",
        "- Very fast and scalable\n",
        "- Simple and efficient\n",
        "- Works well for spherical clusters\n",
        "\n",
        "### Limitations\n",
        "- Must choose `k` manually\n",
        "- Sensitive to initialization\n",
        "- Performs poorly with:\n",
        "  - Different cluster sizes\n",
        "  - Non-spherical shapes\n",
        "  - Outliers\n"
      ],
      "metadata": {
        "id": "1lR1i9APGjqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "63O-RJhdHLMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Centroid Initialization Methods in k-Means\n",
        "\n",
        "The k-means algorithm is sensitive to centroid initialization. Poor initialization can lead to suboptimal clustering.\n",
        "\n",
        "There are several strategies to mitigate this issue.\n"
      ],
      "metadata": {
        "id": "0wMQwusWHMf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "SvOFO77jHWvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Initialization\n",
        "\n",
        "If you already have a good idea of where centroids should be (for example, from a previous clustering run), you can manually specify them.\n"
      ],
      "metadata": {
        "id": "mC0Nw9uTHXgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "good_init = np.array([\n",
        "    [-3, 3],\n",
        "    [-3, 2],\n",
        "    [-3, 1],\n",
        "    [-1, 2],\n",
        "    [0, 2]\n",
        "])\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, init=good_init, random_state=42)\n",
        "kmeans.fit(X)\n"
      ],
      "metadata": {
        "id": "uBCYbHbdHYSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Random Initializations (`n_init`)\n",
        "\n",
        "Another approach is to run k-means multiple times with different random initializations and keep the best solution.\n",
        "\n",
        "The `n_init` hyperparameter controls how many times the algorithm runs with different initial centroids.\n"
      ],
      "metadata": {
        "id": "Q7ZquinSHY_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters=5,\n",
        "    init=\"random\",\n",
        "    n_init=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "kmeans.fit(X)\n"
      ],
      "metadata": {
        "id": "Tofd16RYHbDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inertia\n",
        "\n",
        "To decide which initialization is best, k-means uses **inertia**.\n",
        "\n",
        "**Inertia** is defined as the sum of squared distances between each instance and its closest centroid.\n"
      ],
      "metadata": {
        "id": "bvfiObEqHb90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.inertia_\n"
      ],
      "metadata": {
        "id": "fICq5PaEHiQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `score()` method returns the **negative inertia** (because higher scores are considered better in Scikit-Learn).\n"
      ],
      "metadata": {
        "id": "N0CnoXhwHt9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.score(X)\n"
      ],
      "metadata": {
        "id": "rX66rE82Hu0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-Means++\n",
        "\n",
        "k-means++ is a smarter centroid initialization algorithm that spreads centroids far apart.\n",
        "\n",
        "It greatly reduces the risk of poor clustering and usually converges faster.\n"
      ],
      "metadata": {
        "id": "U5x4lTJhHvrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k-Means++ Algorithm\n",
        "\n",
        "1. Choose one centroid randomly from the dataset.\n",
        "2. Choose the next centroid with probability proportional to the squared distance from the closest existing centroid.\n",
        "3. Repeat until k centroids are chosen.\n"
      ],
      "metadata": {
        "id": "LLck3uDvHyEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters=5,\n",
        "    init=\"k-means++\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "kmeans.fit(X)\n"
      ],
      "metadata": {
        "id": "WPIKFdrWHzca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using k-means++, `n_init` defaults to 1 because initialization quality is already high.\n"
      ],
      "metadata": {
        "id": "78hhJ86cH1KD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accelerated k-Means and Mini-Batch k-Means\n"
      ],
      "metadata": {
        "id": "px5pXOjdIVZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elkan’s Accelerated k-Means\n",
        "\n",
        "Elkan’s algorithm speeds up k-means by avoiding unnecessary distance computations using the triangle inequality.\n",
        "\n",
        "It can speed up training on some datasets, but may slow it down on others.\n"
      ],
      "metadata": {
        "id": "j5qW5fbcIW93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters=5,\n",
        "    algorithm=\"elkan\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "kmeans.fit(X)\n"
      ],
      "metadata": {
        "id": "DxFvLaQgIYCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-Batch k-Means\n",
        "\n",
        "Mini-batch k-means uses small random subsets of the data to update centroids.\n",
        "\n",
        "This allows clustering of very large datasets that do not fit in memory.\n"
      ],
      "metadata": {
        "id": "yHKmZx_mIZBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "minibatch_kmeans = MiniBatchKMeans(\n",
        "    n_clusters=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "minibatch_kmeans.fit(X)\n"
      ],
      "metadata": {
        "id": "mb-qvJpkIZxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the Optimal Number of Clusters\n"
      ],
      "metadata": {
        "id": "SjlI34LhIa0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Elbow Method\n",
        "\n",
        "Inertia always decreases as k increases, so we look for an **elbow** in the inertia curve.\n"
      ],
      "metadata": {
        "id": "mJFo-9EOIb82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Elbow Method\n",
        "\n",
        "Inertia always decreases as k increases, so we look for an **elbow** in the inertia curve.\n"
      ],
      "metadata": {
        "id": "Fu52JXyxIax6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inertias = []\n",
        "ks = range(1, 11)\n",
        "\n",
        "for k in ks:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "    inertias.append(kmeans.inertia_)\n"
      ],
      "metadata": {
        "id": "qTnZmteDIdJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(ks, inertias, \"bo-\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qhj_udcCIfzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Silhouette Score\n",
        "\n",
        "The silhouette score measures how well instances fit within their cluster compared to other clusters.\n"
      ],
      "metadata": {
        "id": "3Zd7LiSvIgkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "labels = kmeans.fit_predict(X)\n",
        "\n",
        "silhouette_score(X, labels)\n"
      ],
      "metadata": {
        "id": "2vRyfm1GIhmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limits of k-Means\n",
        "\n",
        "k-means struggles when:\n",
        "- Clusters have different sizes\n",
        "- Clusters have different densities\n",
        "- Clusters are non-spherical\n"
      ],
      "metadata": {
        "id": "IAc_ob0MIqT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Always scale features before using k-means to improve performance.\n"
      ],
      "metadata": {
        "id": "D9Tv13kzIuXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Segmentation Using k-Means\n"
      ],
      "metadata": {
        "id": "28eBM4jxIvd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as Image\n",
        "\n",
        "image = np.asarray(Image.open(filepath))\n",
        "image.shape\n"
      ],
      "metadata": {
        "id": "7rBAR8m4IwrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pixels = image.reshape(-1, 3)\n",
        "\n",
        "kmeans = KMeans(n_clusters=8, random_state=42)\n",
        "kmeans.fit(X_pixels)\n",
        "\n",
        "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
        "segmented_img = segmented_img.reshape(image.shape)\n"
      ],
      "metadata": {
        "id": "vEmS3tnRIx7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(segmented_img.astype(np.uint8))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YlHOZvhaIy8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi-Supervised Learning with k-Means\n"
      ],
      "metadata": {
        "id": "PYeaPCNyIz5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "X_digits, y_digits = load_digits(return_X_y=True)\n",
        "X_train, y_train = X_digits[:1400], y_digits[:1400]\n",
        "X_test, y_test = X_digits[1400:], y_digits[1400:]\n"
      ],
      "metadata": {
        "id": "019uGhczI0r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "n_labeled = 50\n",
        "log_reg = LogisticRegression(max_iter=10_000)\n",
        "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])\n",
        "\n",
        "log_reg.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "05-9g6VgI6rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering the Training Set\n"
      ],
      "metadata": {
        "id": "5ee5hlcuI-4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 50\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "X_digits_dist = kmeans.fit_transform(X_train)\n",
        "\n",
        "representative_idx = X_digits_dist.argmin(axis=0)\n",
        "X_representative_digits = X_train[representative_idx]\n"
      ],
      "metadata": {
        "id": "jMOk_2h0JCK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Representative labels are assumed to be manually provided.)\n"
      ],
      "metadata": {
        "id": "Tm2VyMVYJMIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_representative_digits = np.array([\n",
        "    8, 0, 1, 3, 6, 7, 5, 4, 2, 8,\n",
        "    # ...\n",
        "])\n"
      ],
      "metadata": {
        "id": "dv2eAKWDJNX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(max_iter=10_000)\n",
        "log_reg.fit(X_representative_digits, y_representative_digits)\n",
        "\n",
        "log_reg.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "BzM5ZBsYJRd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Propagation\n"
      ],
      "metadata": {
        "id": "TN5I5l8UJSxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_propagated = np.empty(len(X_train), dtype=np.int64)\n",
        "\n",
        "for i in range(k):\n",
        "    y_train_propagated[kmeans.labels_ == i] = y_representative_digits[i]\n"
      ],
      "metadata": {
        "id": "rtwAbHVYJT0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(max_iter=10_000)\n",
        "log_reg.fit(X_train, y_train_propagated)\n",
        "\n",
        "log_reg.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "l4WIHscmJVTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DBSCAN\n"
      ],
      "metadata": {
        "id": "9SRay1qpJWsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=1000, noise=0.05, random_state=42)\n",
        "\n",
        "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
        "dbscan.fit(X)\n"
      ],
      "metadata": {
        "id": "t-msVzEiJajW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan.labels_\n"
      ],
      "metadata": {
        "id": "t4NhFyuQJbmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instances labeled `-1` are considered anomalies.\n"
      ],
      "metadata": {
        "id": "vkLOxklrJci-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=50)\n",
        "knn.fit(\n",
        "    dbscan.components_,\n",
        "    dbscan.labels_[dbscan.core_sample_indices_]\n",
        ")\n"
      ],
      "metadata": {
        "id": "phuYhtpLJd20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.array([\n",
        "    [-0.5, 0],\n",
        "    [0, 0.5],\n",
        "    [1, -0.1],\n",
        "    [2, 1]\n",
        "])\n",
        "\n",
        "knn.predict(X_new)\n"
      ],
      "metadata": {
        "id": "KAcvtUx_JgMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "- k-means is fast and scalable but sensitive to initialization and cluster shape\n",
        "- k-means++ greatly improves reliability\n",
        "- DBSCAN finds clusters of arbitrary shape and detects anomalies\n",
        "- Different datasets require different clustering strategies\n"
      ],
      "metadata": {
        "id": "wpLAZoWyJjO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Mixture Models (GMMs)\n",
        "\n",
        "A **Gaussian Mixture Model (GMM)** is a probabilistic model that assumes the data was generated from a mixture of several **Gaussian distributions** with unknown parameters.\n",
        "\n",
        "Each Gaussian represents a **cluster**, and unlike k-means:\n",
        "- Clusters can be **elliptical**, not just spherical\n",
        "- Clusters can have **different sizes, orientations, and densities**\n",
        "- Assignments are **soft** (probabilities), not hard\n",
        "\n",
        "A GMM assumes:\n",
        "- There are `k` clusters\n",
        "- Each cluster `j` has:\n",
        "  - weight \\( \\phi^{(j)} \\)\n",
        "  - mean \\( \\mu^{(j)} \\)\n",
        "  - covariance matrix \\( \\Sigma^{(j)} \\)\n",
        "\n",
        "Scikit-Learn implements this using the **Expectation-Maximization (EM)** algorithm.\n"
      ],
      "metadata": {
        "id": "cy0Xs29jOGxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Fit a Gaussian Mixture Model with 3 clusters\n",
        "gm = GaussianMixture(n_components=3, n_init=10, random_state=42)\n",
        "gm.fit(X)\n"
      ],
      "metadata": {
        "id": "bxBL_hSaJiY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learned Parameters\n",
        "\n",
        "After fitting, the model estimates:\n",
        "- Cluster weights\n",
        "- Means\n",
        "- Covariance matrices\n"
      ],
      "metadata": {
        "id": "8enzIpWHOMBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm.weights_\n"
      ],
      "metadata": {
        "id": "Z1zz28AwOM7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gm.means_\n"
      ],
      "metadata": {
        "id": "bAA27lo1ON-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gm.covariances_\n"
      ],
      "metadata": {
        "id": "S_j9x7kYOOvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These correspond to:\n",
        "- **weights** → relative size of each cluster  \n",
        "- **means** → cluster centers  \n",
        "- **covariances** → shape and orientation of clusters  \n"
      ],
      "metadata": {
        "id": "hTubPMGdOPfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expectation–Maximization (EM) Algorithm\n",
        "\n",
        "The **EM algorithm** alternates between two steps:\n",
        "\n",
        "### Expectation step (E-step)\n",
        "Estimate the probability that each instance belongs to each cluster  \n",
        "(these probabilities are called **responsibilities**).\n",
        "\n",
        "### Maximization step (M-step)\n",
        "Update:\n",
        "- cluster means\n",
        "- covariance matrices\n",
        "- cluster weights  \n",
        "\n",
        "using the responsibilities.\n",
        "\n",
        "Unlike k-means:\n",
        "- All points influence all clusters\n",
        "- Influence is weighted by probability\n",
        "\n",
        "⚠️ EM can converge to poor local optima, so multiple initializations (`n_init`) are important.\n"
      ],
      "metadata": {
        "id": "gidn8XwqOQsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm.converged_, gm.n_iter_\n"
      ],
      "metadata": {
        "id": "P0Ym-c3lORtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hard vs Soft Clustering\n",
        "\n",
        "- **Hard clustering** assigns each instance to the most likely cluster\n",
        "- **Soft clustering** returns probabilities for each cluster\n"
      ],
      "metadata": {
        "id": "bUL4p6SDOh7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm.predict(X)\n"
      ],
      "metadata": {
        "id": "22mVFiOXOkSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gm.predict_proba(X).round(3)\n"
      ],
      "metadata": {
        "id": "n2SuBLgtOlJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative Models\n",
        "\n",
        "GMMs are **generative models**, meaning we can sample new instances from the learned distributions.\n"
      ],
      "metadata": {
        "id": "mdgO3QNROl8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new, y_new = gm.sample(6)\n",
        "X_new, y_new\n"
      ],
      "metadata": {
        "id": "cPf9GMhqOmle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Density Estimation\n",
        "\n",
        "The `score_samples()` method returns the **log probability density** at each point.\n",
        "\n",
        "- Higher value → higher density\n",
        "- These are **log-PDF values**, not probabilities\n"
      ],
      "metadata": {
        "id": "Mx6m5XtaOpB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm.score_samples(X).round(2)\n"
      ],
      "metadata": {
        "id": "JYzDZsoQOp-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Covariance Constraints\n",
        "\n",
        "You can restrict cluster shapes using `covariance_type`:\n",
        "\n",
        "| Type | Description |\n",
        "|----|----|\n",
        "| `\"full\"` | Any shape, size, orientation (default) |\n",
        "| `\"tied\"` | All clusters share the same covariance |\n",
        "| `\"diag\"` | Ellipses aligned with axes |\n",
        "| `\"spherical\"` | Spheres with different radii |\n"
      ],
      "metadata": {
        "id": "XuKopmhzOq2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm_spherical = GaussianMixture(\n",
        "    n_components=3,\n",
        "    covariance_type=\"spherical\",\n",
        "    n_init=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gm_spherical.fit(X)\n"
      ],
      "metadata": {
        "id": "YAOOJE2YPdxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anomaly Detection with GMMs\n",
        "\n",
        "Instances in **low-density regions** can be treated as anomalies.\n",
        "\n",
        "A common approach:\n",
        "1. Compute density scores\n",
        "2. Choose a percentile threshold (e.g., lowest 2%)\n",
        "3. Flag points below that threshold\n"
      ],
      "metadata": {
        "id": "YacvP1iYPehz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "densities = gm.score_samples(X)\n",
        "threshold = np.percentile(densities, 2)\n",
        "\n",
        "anomalies = X[densities < threshold]\n"
      ],
      "metadata": {
        "id": "wyBnc-BVPgqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing the Number of Clusters\n",
        "\n",
        "Gaussian mixtures use **information criteria**:\n",
        "\n",
        "- **AIC** → favors better fit\n",
        "- **BIC** → favors simpler models\n",
        "\n",
        "Lower values are better.\n"
      ],
      "metadata": {
        "id": "3CcZbGypPhYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gm.aic(X), gm.bic(X)\n"
      ],
      "metadata": {
        "id": "12eTRl6EPia_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Gaussian Mixture Models\n",
        "\n",
        "`BayesianGaussianMixture` can automatically eliminate unnecessary clusters by assigning them near-zero weight.\n"
      ],
      "metadata": {
        "id": "qdM3PO8sPjKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "\n",
        "bgm = BayesianGaussianMixture(\n",
        "    n_components=10,\n",
        "    n_init=10,\n",
        "    max_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "bgm.fit(X)\n",
        "bgm.weights_.round(2)\n"
      ],
      "metadata": {
        "id": "1DDp-f1bPj9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limitations of Gaussian Mixtures\n",
        "\n",
        "GMMs struggle when clusters:\n",
        "- Are **non-ellipsoidal**\n",
        "- Have complex shapes (e.g., two moons)\n",
        "\n",
        "They may split one cluster into many ellipses.\n"
      ],
      "metadata": {
        "id": "RHE20KdPPk3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Anomaly and Novelty Detection Algorithms\n",
        "\n",
        "Scikit-Learn also provides:\n",
        "\n",
        "- **EllipticEnvelope** (robust Gaussian fit)\n",
        "- **Isolation Forest** (random partitioning)\n",
        "- **Local Outlier Factor (LOF)** (density comparison)\n",
        "- **One-Class SVM** (novelty detection)\n",
        "- **PCA reconstruction error**\n",
        "\n",
        "Each method has different strengths depending on dataset size, dimensionality, and noise.\n"
      ],
      "metadata": {
        "id": "gxYYwaU0PllG"
      }
    }
  ]
}